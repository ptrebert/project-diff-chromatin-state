{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "import os as os\n",
    "\n",
    "from bs4 import BeautifulSoup as bsoup\n",
    "import requests as req\n",
    "import pandas as pd\n",
    "\n",
    "remc_data = 'http://egg2.wustl.edu/roadmap/data'\n",
    "\n",
    "npeak_url = os.path.join(remc_data, 'byFileType/peaks/consolidated/narrowPeak')\n",
    "bpeak_url = os.path.join(remc_data, 'byFileType/peaks/consolidated/broadPeak')\n",
    "hotspot_url = os.path.join(remc_data, 'byFileType/peaks/consolidated/broadPeak/DNase')\n",
    "seg_url = os.path.join(remc_data, 'byFileType/chromhmmSegmentations/ChmmModels/core_K27ac/jointModel/final')\n",
    "exp_url = os.path.join(remc_data, 'byDataType/rna/expression')\n",
    "\n",
    "repo_base = '/home/pebert/work/code/mpggit/statediff'\n",
    "project_base = '/TL/deep/fhgfs/projects/pebert/thesis/projects/statediff'\n",
    "\n",
    "dl_dest = os.path.join(project_base, 'loaded_input/remc')\n",
    "\n",
    "dl_subdirs = {'/css': 'state_seg', '/dnase_narrow': 'dnase_peaks',\n",
    "              '/hist_narrow': 'hist_peaks', '/hist_broad': 'hist_peaks'}\n",
    "\n",
    "dl_ext = {'/css': 'segments.bed', '/dnase_narrow': 'macs2.npeak.gz',\n",
    "          '/hist_narrow': 'macs2.npeak.gz', '/hist_broad': 'macs2.bpeak.gz'}\n",
    "\n",
    "cache_file = os.path.join(repo_base, 'annotation', 'remc_cache.h5')\n",
    "\n",
    "histone_libs = ['H3K4me1', 'H3K4me3', 'H3K36me3',\n",
    "                'H3K27me3', 'H3K9me3', 'H3K27ac', 'Input']\n",
    "\n",
    "remove_ids = [('E104', 'bad H3K36me3'), ('E098', 'weak H3K27me3'),\n",
    "              ('E113', 'weak H3K27me3'), ('E114', 'low quality rating')]\n",
    "\n",
    "def search_expression_eids():\n",
    "    url = os.path.join(remc_data, 'byDataType/rna/expression/EG.name.txt')\n",
    "    df = pd.read_csv(url, sep='\\t', header=0, names=['EID', 'desc'])\n",
    "    df.dropna(axis=0, how='any', inplace=True)\n",
    "    return df\n",
    "\n",
    "def search_peak_ids(base_url, file_ext, assay):\n",
    "    resp = req.get(base_url)\n",
    "    infos = resp.text\n",
    "    soup = bsoup(infos, 'lxml')\n",
    "    collector = []\n",
    "    for link in soup.find_all('a'):\n",
    "        item = link.get('href')\n",
    "        if item.endswith(file_ext):\n",
    "            load_url = os.path.join(base_url, item)\n",
    "            eid, remain = item.split('-')\n",
    "            lib, _ = remain.split('.', 1)\n",
    "            if assay == lib:  # DNase\n",
    "                collector.append([eid, lib, file_ext, load_url])\n",
    "                continue\n",
    "            else:\n",
    "                if assay == 'histone' and lib in histone_libs:\n",
    "                    collector.append([eid, lib, file_ext, load_url])\n",
    "    df = pd.DataFrame(collector, columns=['EID', 'library', 'file_ext', 'file_url'])\n",
    "    return df\n",
    "\n",
    "def search_segment_ids(base_url, file_ext):\n",
    "    resp = req.get(base_url)\n",
    "    infos = resp.text\n",
    "    soup = bsoup(infos, 'lxml')\n",
    "    collector = []\n",
    "    for link in soup.find_all('a'):\n",
    "        item = link.get('href')\n",
    "        if item.endswith(file_ext):\n",
    "            load_url = os.path.join(base_url, item)\n",
    "            eid, remain = item.split('_', 1)\n",
    "            lib, _ = remain.split('.', 1)\n",
    "            collector.append([eid, '18state', file_ext, load_url])\n",
    "    df = pd.DataFrame(collector, columns=['EID', 'library', 'file_ext', 'file_url'])\n",
    "    return df\n",
    "\n",
    "def identify_shared_eids(cache_path):\n",
    "    expression = search_expression_eids()\n",
    "    hist_npeak = search_peak_ids(npeak_url, 'narrowPeak.gz', 'histone')\n",
    "    dnase_npeak = search_peak_ids(npeak_url, 'narrowPeak.gz', 'DNase')\n",
    "    hist_bpeak = search_peak_ids(bpeak_url, 'broadPeak.gz', 'histone')\n",
    "    # for some reason, DNase Hotspots limit the selection to 19 samples\n",
    "    #dnase_hspot = search_peak_ids(hotspot_url, 'fdr0.01.broad.bed.gz', 'DNase')\n",
    "    css = search_segment_ids(seg_url, 'segments.bed')\n",
    "        \n",
    "    shared_eids = set(expression['EID'].tolist())\n",
    "    for data in [hist_npeak, dnase_npeak, hist_bpeak, css]:\n",
    "        this_set = set(data['EID'].tolist())\n",
    "        shared_eids = shared_eids.intersection(this_set)\n",
    "    shared_eids = shared_eids - set([t[0] for t in remove_ids])\n",
    "    \n",
    "    with pd.HDFStore(cache_path, 'w', complib='blosc', complevel=9) as hdf:\n",
    "        expression = expression.loc[expression['EID'].isin(shared_eids), :]\n",
    "        hdf.put('samples', expression, format='table')\n",
    "        hist_npeak = hist_npeak.loc[hist_npeak['EID'].isin(shared_eids), :]\n",
    "        hdf.put('hist_narrow', hist_npeak, format='table')\n",
    "        hist_bpeak = hist_bpeak.loc[hist_bpeak['EID'].isin(shared_eids), :]\n",
    "        hdf.put('hist_broad', hist_bpeak, format='table')\n",
    "        dnase_npeak = dnase_npeak.loc[dnase_npeak['EID'].isin(shared_eids), :]\n",
    "        hdf.put('dnase_narrow', dnase_npeak, format='table')\n",
    "        css = css.loc[css['EID'].isin(shared_eids), :]\n",
    "        hdf.put('css', css, format='table')\n",
    "    return\n",
    "\n",
    "def download_remc_data(cache):\n",
    "    \n",
    "    load_log = []\n",
    "    with pd.HDFStore(cache, 'r') as hdf:\n",
    "        for k in hdf.keys():\n",
    "            if k == '/load_log':\n",
    "                continue\n",
    "            if k != '/samples':\n",
    "                subdir = dl_subdirs[k]\n",
    "                file_ext = dl_ext[k]\n",
    "                target_dir = os.path.join(dl_dest, subdir)\n",
    "                if not os.path.isdir(target_dir):\n",
    "                    os.makedirs(target_dir, exist_ok=True)\n",
    "                data = hdf[k]\n",
    "                for row in data.itertuples():\n",
    "                    src_url = row.file_url\n",
    "                    trg_file = '_'.join([row.EID, row.library, file_ext])\n",
    "                    trg_path = os.path.join(target_dir, trg_file)\n",
    "                    load_log.append([row.EID, row.library, src_url, trg_file])\n",
    "                    if not os.path.isfile(trg_path):\n",
    "                        resp = req.get(src_url)\n",
    "                        if 'segments' in trg_file:\n",
    "                            with open(trg_path, 'w') as dump:\n",
    "                                dump.write(resp.text)\n",
    "                        else:\n",
    "                            with open(trg_path, 'wb') as dump:\n",
    "                                dump.write(resp.content)\n",
    "    df_log = pd.DataFrame(load_log, columns=['EID', 'library', 'source', 'target'])\n",
    "    with pd.HDFStore(cache, 'a') as hdf:\n",
    "        hdf.put('load_log', df_log, format='table')\n",
    "    return\n",
    "\n",
    "\n",
    "def download_remc_expression():\n",
    "    resp = req.get(exp_url)\n",
    "    infos = resp.text\n",
    "    soup = bsoup(infos, 'lxml')\n",
    "    dl_folder = os.path.join(dl_dest, 'rna_data')\n",
    "    for link in soup.find_all('a'):\n",
    "        item = link.get('href')\n",
    "        if item.endswith('rb.gz'):\n",
    "            continue  # ignore ribosomal genes\n",
    "        elif item.endswith('.gz'):\n",
    "            src_url = os.path.join(exp_url, item)\n",
    "            trg_file = item\n",
    "            trg_path = os.path.join(dl_folder, trg_file)\n",
    "            if not os.path.isfile(trg_path):\n",
    "                resp = req.get(src_url)\n",
    "                with open(trg_path, 'wb') as dump:\n",
    "                    dump.write(resp.content)\n",
    "        else:\n",
    "            continue\n",
    "    return\n",
    "\n",
    "def load_remc_data():\n",
    "    if not os.path.isfile(cache_file):\n",
    "        identify_shared_eids(cache_file)\n",
    "    download_remc_data(cache_file)\n",
    "    download_remc_expression()\n",
    "    return True\n",
    "    \n",
    "    \n",
    "        \n",
    "load_remc_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}