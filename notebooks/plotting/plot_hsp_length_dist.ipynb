{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os as os\n",
    "import collections as col\n",
    "import itertools as itt\n",
    "import pickle as pck\n",
    "import time as ti\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as rng\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# What does this do?\n",
    "# Plot a histogram of the HSP length\n",
    "# distribution (intended for merged HSPs)\n",
    "\n",
    "date = '20180403'\n",
    "\n",
    "run_plot_hsp_length_dist = True\n",
    "\n",
    "save_figures = True\n",
    "\n",
    "sns.set(style='white',\n",
    "        font_scale=1.5,\n",
    "        rc={'font.family': ['sans-serif'],\n",
    "            'font.sans-serif': ['DejaVu Sans']})\n",
    "\n",
    "fhgfs_base = '/TL/deep/fhgfs/projects/pebert/thesis/projects/statediff'\n",
    "cache_dir = os.path.join(fhgfs_base, 'caching/notebooks')\n",
    "\n",
    "hsp_files_folder = os.path.join(fhgfs_base, 'solidstate/deep')\n",
    "\n",
    "base_out = '/TL/deep-external01/nobackup/pebert/cloudshare/mpiinf/phd/chapter_projects/statediff'\n",
    "fig_supp = os.path.join(base_out, 'figures', 'pub', 'supp')\n",
    "fig_main = os.path.join(base_out, 'figures', 'pub', 'main')\n",
    "fig_collect = os.path.join(base_out, 'figures', 'pub', 'collection')\n",
    "                   \n",
    "    \n",
    "def collect_hsp_data(rootfolder):\n",
    "    collector = col.defaultdict(list)\n",
    "    for root, dirs, datafiles in os.walk(rootfolder):\n",
    "        if root.endswith('hsp_run') and datafiles:\n",
    "            for df in datafiles:\n",
    "                # deep_hsp_hg38_ecs10_CELLTYPE_HG_vs_CELLTYPE_Ma.h5\n",
    "                infos = df.split('.')[0].split('_')\n",
    "                seg = infos[3]\n",
    "                c1, c2 = infos[5], infos[8]\n",
    "                fpath = os.path.join(root, df)\n",
    "                with pd.HDFStore(fpath, 'r') as hdf:\n",
    "                    for k in hdf.keys():\n",
    "                        if k.startswith('/segments') and not k.endswith('/thresholds'):\n",
    "                            _, _, scoring, chrom = k.split('/')\n",
    "                            data = hdf[k]\n",
    "                            sizes = data['num_bins'].values.tolist()\n",
    "                            collector[(seg, c1, c2, scoring)].extend(sizes)\n",
    "    return collector\n",
    "    \n",
    "\n",
    "def collect_region_overlaps(paths):\n",
    "    col_names = ['chrom', 'start', 'end', 'name', 'score',\n",
    "                 'segpv', 'sumpv', 'sample1', 'sample2', 'rank', 'pct']\n",
    "    columns = [c + '_A' for c in col_names]\n",
    "    columns.extend([c + '_B' for c in col_names])\n",
    "    columns.append('overlap')\n",
    "    collector = col.defaultdict(col.Counter)\n",
    "    for path in paths:\n",
    "        for root, dirs, tables in os.walk(path):\n",
    "            if tables:\n",
    "                for t in tables:\n",
    "                    if t.endswith('.tsv'):\n",
    "                        file_id1, file_id2 = t.split('.')[0].split('-isect-')\n",
    "                        tpath = os.path.join(root, t)\n",
    "                        ovl = pd.read_csv(tpath, sep='\\t', header=None,\n",
    "                                          names=columns, usecols=['sample1_A', 'sample2_A',\n",
    "                                                                  'sample1_B', 'sample2_B',\n",
    "                                                                  'overlap'])\n",
    "                        ovl['overlap'] = ovl['overlap'].astype(np.int32)\n",
    "                        shared = ovl.groupby(['sample1_A', 'sample2_A', 'sample1_B',\n",
    "                                              'sample2_B'])['overlap'].sum()\n",
    "                        shared = shared.astype(np.int32)\n",
    "                        collector[file_id1, file_id2].update(shared.to_dict())\n",
    "    return collector\n",
    "\n",
    "\n",
    "def build_jaccard_dist_matrix(totals, shared, selectors, add_score=False, add_segment=False):\n",
    "    jaccard = []\n",
    "    labels = []\n",
    "    for (file_a, file_b), overlaps in shared.items():\n",
    "        if all([(s in file_a) and (s in file_b) for s in selectors]):\n",
    "            for (a1, a2, b1, b2), ovl in overlaps.items():\n",
    "                a_totals = totals[file_a][(a1, a2)]\n",
    "                b_totals = totals[file_b][(b1, b2)] \n",
    "                j = np.round(ovl / (a_totals + b_totals - ovl), 3)                    \n",
    "                a_label = a1[7] + a1[8] + a1[3] + ' v ' + a2[7] + a2[8] + a2[3]\n",
    "                b_label = b1[7] + b1[8] + b1[3] + ' v ' + b2[7] + b2[8] + b2[3]\n",
    "                if add_score:\n",
    "                    a_label += ' ' + file_a.split('_')[-1][0].capitalize()\n",
    "                    b_label += ' ' + file_b.split('_')[-1][0].capitalize()\n",
    "                if add_segment:\n",
    "                    seg_a = file_a.split('_')[0]\n",
    "                    seg_a = seg_a[0].capitalize() + seg_a[-1]\n",
    "                    a_label += ' ' + seg_a\n",
    "                    seg_b = file_b.split('_')[0]\n",
    "                    seg_b = seg_b[0].capitalize() + seg_b[-1]\n",
    "                    b_label += ' ' + seg_b\n",
    "                jaccard.append((a_label, b_label, j))\n",
    "                jaccard.append((b_label, a_label, j))\n",
    "                labels.extend([a_label, b_label])\n",
    "    labels = sorted(set(labels))\n",
    "    dim = len(labels)\n",
    "    df = pd.DataFrame(np.zeros((dim, dim), dtype=np.float32),\n",
    "                      index=labels, columns=labels)\n",
    "    for r, c, j in jaccard:\n",
    "        df.loc[r, c] = j\n",
    "    return df    \n",
    "\n",
    "\n",
    "def create_histogram(data, title):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    pct = 100\n",
    "    pct_75 = np.percentile(data, 75)\n",
    "    # make this be default \n",
    "    # for vis purposes\n",
    "    pct_99 = np.ceil(np.percentile(data, 99))\n",
    "    data = data[data < pct_99]\n",
    "    pct = 99\n",
    "    \n",
    "    if data.size < 1000:\n",
    "        num_bins = 25\n",
    "    else:\n",
    "        num_bins = 50\n",
    "    label = '{}% ({} bins)'.format(pct, num_bins)\n",
    "    hist = sns.distplot(data, kde=False, rug=False, bins=num_bins,\n",
    "                        ax=ax, color='blue', label=label)\n",
    "    ax.axvline(pct_75, ymax=0.99, color='red',\n",
    "               linestyle='dashed', alpha=0.75, label='75%ile')\n",
    "    plt.legend(loc='upper right')\n",
    "    ax.set_xlabel('HSP size (genomic bins)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    tt = ax.set_title(title)\n",
    "    tt.set_position([0.5, 1.02])\n",
    "    return fig, []\n",
    "    \n",
    "            \n",
    "def plot_hsp_length_dist():\n",
    "    cache_file = os.path.join(cache_dir, '{}_plot_hsp_lendist.pck'.format(date))\n",
    "    if not os.path.isfile(cache_file):\n",
    "        sizes = collect_hsp_data(hsp_files_folder)\n",
    "        with open(cache_file, 'wb') as cache:\n",
    "            pck.dump(sizes, cache)\n",
    "    else:\n",
    "        with open(cache_file, 'rb') as cache:\n",
    "            sizes = pck.load(cache)\n",
    "    tools = set()\n",
    "    comparisons = set()\n",
    "    scorings = set()\n",
    "    for k in sizes.keys():\n",
    "        t, c1, c2, s = k\n",
    "        tools.add(t)\n",
    "        comparisons.add((c1, c2))\n",
    "        scorings.add(s)\n",
    "        \n",
    "    for tool in sorted(tools):\n",
    "        for scoring in sorted(scorings):\n",
    "            for c1, c2 in sorted(comparisons):\n",
    "                dataset = np.array(sizes[(tool, c1, c2, scoring)], dtype=np.int32)\n",
    "                title = 'HSP size dist. (N={}): {} vs {} - '\\\n",
    "                        '{} ({} scoring)'.format(len(dataset), c1, c2, tool.upper(), scoring)\n",
    "                fig, exart = create_histogram(dataset, title)\n",
    "                if save_figures:\n",
    "                    outname = '{}_fig_X_hsp_lendist_{}_{}_{}_vs_{}'.format(date, tool, scoring, c1, c2)\n",
    "                    out_svg = os.path.join(fig_collect, outname + '.svg')\n",
    "                    fig.savefig(out_svg, bbox_inches='tight', extra_artists=exart)\n",
    "                    out_pdf = os.path.join(fig_collect, outname + '.pdf')\n",
    "                    fig.savefig(out_pdf, bbox_inches='tight', extra_artists=exart)\n",
    "                    out_png = os.path.join(fig_collect, outname + '.png')\n",
    "                    fig.savefig(out_png, bbox_inches='tight', extra_artists=exart, dpi=300)\n",
    "                plt.close(fig)\n",
    "    return 0\n",
    "     \n",
    "    \n",
    "if run_plot_hsp_length_dist:\n",
    "    plot_hsp_length_dist()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
