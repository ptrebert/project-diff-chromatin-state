{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os as os\n",
    "import collections as col\n",
    "import itertools as itt\n",
    "import pickle as pck\n",
    "import time as ti\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as rng\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# What does this do?\n",
    "# Plot HSP scores vs p-values\n",
    "# and indicate all possible threshold\n",
    "# values derived either by rules from\n",
    "# the literature or by sampling\n",
    "\n",
    "date = '20180405'\n",
    "\n",
    "run_plot_score_thresholds = True\n",
    "\n",
    "save_figures = True\n",
    "\n",
    "sns.set(style='white',\n",
    "        font_scale=1.5,\n",
    "        rc={'font.family': ['sans-serif'],\n",
    "            'font.sans-serif': ['DejaVu Sans']})\n",
    "\n",
    "fhgfs_base = '/TL/deep/fhgfs/projects/pebert/thesis/projects/statediff'\n",
    "cache_dir = os.path.join(fhgfs_base, 'caching/notebooks')\n",
    "\n",
    "hsp_files_folder = os.path.join(fhgfs_base, 'solidstate/deep')\n",
    "\n",
    "base_out = '/TL/deep-external01/nobackup/pebert/cloudshare/mpiinf/phd/chapter_projects/statediff'\n",
    "fig_supp = os.path.join(base_out, 'figures', 'pub', 'supp')\n",
    "fig_main = os.path.join(base_out, 'figures', 'pub', 'main')\n",
    "fig_collect = os.path.join(base_out, 'figures', 'pub', 'collection')\n",
    "                   \n",
    "t_colors = [(102,194,165), (252,141,98), (141,160,203),\n",
    "            (231,138,195), (166,216,84)]\n",
    "t_colors = list(map(lambda x: (x[0]/255, x[1]/255, x[2]/255), t_colors))\n",
    "\n",
    "    \n",
    "def collect_hsp_threshold_data(rootfolder, cache_file):\n",
    "    filemode = 'w'\n",
    "    for root, dirs, datafiles in os.walk(rootfolder):\n",
    "        if root.endswith('hsp_run') and datafiles:\n",
    "            for df in datafiles:\n",
    "                if not df.endswith('.h5'):\n",
    "                    continue\n",
    "                if 'cmm18' not in df:\n",
    "                    continue\n",
    "                infos = df.split('.')[0].split('_')\n",
    "                seg = infos[3]\n",
    "                c1, c2 = infos[5], infos[8]\n",
    "                fpath = os.path.join(root, df)\n",
    "                this_data = []\n",
    "                this_thresholds = None\n",
    "                scoring = None\n",
    "                with pd.HDFStore(fpath, 'r') as hdf:\n",
    "                    md = hdf['/metadata/comparisons']\n",
    "                    sample_pairs = set(md['sample1']).union(set(md['sample2']))\n",
    "                    for k in hdf.keys():\n",
    "                        if k.startswith('/segments'):\n",
    "                            if k.endswith('/thresholds'):\n",
    "                                _, _, scoring, _ = k.split('/')\n",
    "                                this_thresholds = hdf[k]\n",
    "                                continue\n",
    "                            this_data.append(hdf[k])\n",
    "                this_data = pd.concat(this_data, axis=0, ignore_index=False)\n",
    "                this_data.reset_index(drop=True, inplace=True)\n",
    "                this_data = this_data.loc[:, ['norm_nat_score', 'segment_pv', 'summed_pv']]\n",
    "                assert scoring is not None, 'Path to saved: {}'.format(df)\n",
    "                sample_t = collect_sampling_thresholds(root.replace('hsp_run', 'smp_run'),\n",
    "                                                       scoring, sample_pairs)\n",
    "                if sample_t is not None:\n",
    "                    this_thresholds = pd.concat([this_thresholds, sample_t], axis=1, ignore_index=False)\n",
    "                with pd.HDFStore(cache_file, filemode) as hdf:\n",
    "                    hdf.put(os.path.join(seg, c1, c2, scoring, 'data'), this_data)\n",
    "                    hdf.put(os.path.join(seg, c1, c2, scoring, 'thresholds'), this_thresholds)\n",
    "                filemode = 'a'\n",
    "    return cache_file\n",
    "    \n",
    "\n",
    "def collect_sampling_thresholds(basefolder, scoring, samples):\n",
    "    collector = None\n",
    "    for smpfile in os.listdir(basefolder):\n",
    "        if smpfile.endswith('.h5'):\n",
    "            # change after update\n",
    "            smptype = smpfile.split('.')[0].split('_')[-1]\n",
    "            smptype = {'smprep': 'replicate', 'smprand': 'random'}[smptype]\n",
    "            fpath = os.path.join(basefolder, smpfile)\n",
    "            with pd.HDFStore(fpath, 'r') as hdf:\n",
    "                # change after update\n",
    "                load_keys = [k for k in hdf.keys() if k.startswith('/sstsmp') and scoring in k]\n",
    "                assert load_keys, 'No data to load for scoring {} (path {})'.format(scoring, basefolder)\n",
    "                dataset = []\n",
    "                for k in load_keys:\n",
    "                    chrom_data = hdf[k]\n",
    "                    chrom_data['chrom'] = k.split('/')[-1]\n",
    "                    dataset.append(chrom_data)\n",
    "                dataset = pd.concat(dataset, axis=0, ignore_index=False)\n",
    "                if smptype == 'replicate':\n",
    "                    row_idx1 = np.array(dataset['sample1'].isin(samples), dtype=np.bool)\n",
    "                    row_idx2 = np.array(dataset['sample2'].isin(samples), dtype=np.bool)\n",
    "                    row_idx = np.logical_and(row_idx1, row_idx2)\n",
    "                    dataset = dataset.loc[row_idx, :].copy()\n",
    "                dataset = dataset.groupby('chrom')['norm_nat_score'].mean()\n",
    "                dataset.name = smptype + '_lo'\n",
    "                dataset = dataset.to_frame()\n",
    "                if collector is None:\n",
    "                    collector = dataset\n",
    "                else:\n",
    "                    collector = pd.concat([collector, dataset], axis=1, ignore_index=False)\n",
    "    return collector\n",
    "    \n",
    "    \n",
    "def create_score_scatter(data, thresholds, title):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    \n",
    "    xvals = data['norm_nat_score']\n",
    "    yvals = data['segment_pv']\n",
    "    \n",
    "    zoom_factor = 1\n",
    "    if xvals.max() < 2000:\n",
    "        zoom_factor = 5\n",
    "    elif xvals.max() < 5000:\n",
    "        zoom_factor = 15\n",
    "    else:\n",
    "        zoom_factor = 20\n",
    "    \n",
    "    ax.set_ylim(-10, yvals.max() + 25)\n",
    "        \n",
    "    ax.scatter(xvals, yvals, s=10, c='dodgerblue', marker='o',\n",
    "               label=None)\n",
    "    \n",
    "    axins = zoomed_inset_axes(ax, zoom_factor, loc='lower right')\n",
    "    axins.scatter(xvals, yvals, s=5, c='dodgerblue', marker='o',\n",
    "                  label=None)\n",
    "    \n",
    "    t_vals = []\n",
    "    for t, c in zip(['ferreira_lo', 'loretan_lo', 'quantile_lo',\n",
    "                     'replicate_lo', 'random_lo'],\n",
    "                     t_colors):\n",
    "                    #['red', 'darkviolet', 'darkorange']):\n",
    "        t_val = thresholds[t].mean()\n",
    "        t_vals.append(t_val)\n",
    "        t_label = t.split('_')[0].capitalize()\n",
    "        ax.axvline(t_val, ymin=0.01, ymax=0.1,\n",
    "                   color=c, linestyle='dashed', linewidth=3,\n",
    "                   label=t_label, zorder=0)\n",
    "        \n",
    "        axins.axvline(t_val, ymin=0.01, ymax=0.99,\n",
    "                      color=c, linestyle='dashed', linewidth=3,\n",
    "                      label=t_label, zorder=0)\n",
    "\n",
    "    t_vals = np.array(t_vals, dtype=np.float32)\n",
    "    t_vals.sort()\n",
    "            \n",
    "    #y_limits = ax.get_ylim()\n",
    "    x0 = max(-5, t_vals.min() - 25)\n",
    "    xn = t_vals.max() + 25\n",
    "    \n",
    "    y0 = -5\n",
    "    if xvals.max() < 2000:\n",
    "        yn = 30\n",
    "    elif xvals.max() < 5000:\n",
    "        yn = 40\n",
    "    else:\n",
    "        yn = 50\n",
    "    axins.set_xlim(x0, xn)\n",
    "    axins.set_ylim(y0, yn)\n",
    "        \n",
    "    axins.yaxis.set_visible(False)\n",
    "    axins.xaxis.set_visible(False)\n",
    "    mark_inset(ax, axins, loc1=2, loc2=3, fc='k', ec='k')\n",
    "\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.set_xlabel('HSP score')\n",
    "    ax.set_ylabel('-log10 (p-value)')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    tt = ax.set_title(title)\n",
    "    tt.set_position([0.5, 1.01])\n",
    "    return fig, []\n",
    "    \n",
    "            \n",
    "def plot_hsp_score_thresholds():\n",
    "    cache_file = os.path.join(cache_dir, '{}_plot_hsp_score_thresholds.h5'.format(date))\n",
    "    if not os.path.isfile(cache_file):\n",
    "        cache_file = collect_hsp_threshold_data(hsp_files_folder, cache_file)\n",
    "    \n",
    "    with pd.HDFStore(cache_file, 'r') as hdf:\n",
    "        for k in hdf.keys():\n",
    "            if k.endswith('thresholds'):\n",
    "                continue\n",
    "            if not k.startswith('/cmm18'):\n",
    "                continue\n",
    "            scores = hdf[k]\n",
    "            thres = hdf[k.replace('data', 'thresholds')]\n",
    "            _, tool, c1, c2, scoring, _ = k.split('/')\n",
    "            plt_title = 'HSP score thresholds: {} vs {} ({} {} scoring)'.format(c1, c2, tool.upper(), scoring)\n",
    "            fig, exart = create_score_scatter(scores, thres, plt_title)\n",
    "            \n",
    "            if save_figures:\n",
    "                outname = '{}_fig_X_hsp_thresholds_{}_{}_{}_vs_{}'.format(date, tool, scoring, c1, c2)\n",
    "                out_svg = os.path.join(fig_collect, outname + '.svg')\n",
    "                fig.savefig(out_svg, bbox_inches='tight', extra_artists=exart)\n",
    "                out_pdf = os.path.join(fig_collect, outname + '.pdf')\n",
    "                fig.savefig(out_pdf, bbox_inches='tight', extra_artists=exart)\n",
    "                out_png = os.path.join(fig_collect, outname + '.png')\n",
    "                fig.savefig(out_png, bbox_inches='tight', extra_artists=exart, dpi=300)\n",
    "            plt.close(fig)\n",
    "    return 0\n",
    "     \n",
    "    \n",
    "if run_plot_score_thresholds:\n",
    "    plot_hsp_score_thresholds()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
